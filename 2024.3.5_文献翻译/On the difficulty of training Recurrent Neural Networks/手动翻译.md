# 关于训练循环神经网络的困难性

## 摘要

在正确训练递归神经网络中有两个众所周知的问题，即Bengio等人详细介绍的消失梯度问题和爆炸梯度问题。(1994).在本文中，我们试图通过从分析、几何和动力系统的角度探讨这些问题来提高对潜在问题的理解。我们的分析被用来证明一个简单而有效的解决方案。本文提出了一种处理爆炸梯度的梯度范数剪切策略和处理梯度消失问题的软约束方法。我们在实验部分验证了我们的假设和提出的解决方案。

## 1. 介绍

一个递归神经网络（RNN），e。g.图1，是80年代提出的一种神经网络模型。，1986年；Elman，1990；Werbos，1988)为建模时间序列。该网络的结构类似于一个标准的多层感知器，有区别的是，我们允许与时间延迟相关联的隐藏单元之间的连接。通过这些连接，该模型可以保留关于过去输入的信息，使其能够发现数据中可能彼此相距遥远的事件之间的时间相关性（这是正确学习时间序列的一个关键属性）。虽然原则上循环网络是一个简单而强大的模型，但在实践中，不幸的是很难进行正确的训练。为什么这个模型如此笨拙的主要原因之一是梯度的消失以及Bengio等人所描述的爆炸性梯度问题。(1994).

![image-20240305130953312](./assets/image-20240305130953312.png)

图1。一个递归神经网络的示意图。隐藏层中的循环连接允许信息从一个输入持续保存到另一个输入。

### 1.1 训练神经网络

## 2. 梯度爆炸和梯度消失

### 2.1 机制

### 2.2 绘制动态系统的相似性

### 2.3 几何解释

## 3. 梯度爆炸和梯度消失的处理

### 3.1 先前的方案

### 3.2 梯度下降

### 3.3 梯度消失的正规化

## 4. 实验与结果

### 4.1 病态合成问题

#### 4.1.1 时间序列问题

#### 4.1.2 其它病理性任务

### 4.2 自然问题

## 5. 总结和结论

## 致谢

我们也要感谢西奥诺开发团队（特别是弗雷德里克·巴斯蒂安，帕斯卡尔·兰布林和詹姆斯·伯格斯特拉）的帮助。我们感谢NSERC，FQRNT，CIFAR，RQCHP和计算加拿大为他们提供的资源。
